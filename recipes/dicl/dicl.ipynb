{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61862dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8033ce8",
   "metadata": {},
   "source": [
    "# Dynamic In-Context Learning\n",
    "\n",
    "This recipe allows TensorZero users to set up a dynamic in-context learning variant for any function.\n",
    "Since TensorZero automatically logs all inferences and feedback, it is straightforward to query a set of good examples and retrieve the most relevant ones to put them into context for future inferences.\n",
    "Since TensorZero allows users to add demonstrations for any inference it is also easy to include them in the set of examples as well.\n",
    "This recipe will show use the OpenAI embeddings API only, but we are working towards support for all embedding providers over time as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5torynfqo9n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load from the root .env file\n",
    "load_dotenv('/home/alchen/claude/tensorzero/.env')\n",
    "\n",
    "print(\"Environment variables loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ecd77",
   "metadata": {},
   "source": [
    "To get started:\n",
    "\n",
    "- Set the `TENSORZERO_CLICKHOUSE_URL` environment variable. For example: `TENSORZERO_CLICKHOUSE_URL=\"http://chuser:chpassword@localhost:8123/tensorzero\"`\n",
    "- Set the `OPENAI_API_KEY` environment variable.\n",
    "- Update the following parameters:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e136f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "CONFIG_PATH = \"../../examples/data-extraction-ner/config/tensorzero.toml\"\n",
    "\n",
    "FUNCTION_NAME = \"extract_entities\"\n",
    "\n",
    "# Can also set this to None if you do not want to use a metric and only want to use demonstrations\n",
    "METRIC_NAME: Optional[str] = None\n",
    "\n",
    "# The name of the DICL variant you will want to use. Set this to a meaningful name that does not conflict\n",
    "# with other variants for the function selected above.\n",
    "DICL_VARIANT_NAME = \"gpt_4o_mini_dicl\"\n",
    "\n",
    "# The model to use for the DICL variant.\n",
    "DICL_EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# The model to use for generation in the DICL variant.\n",
    "DICL_GENERATION_MODEL = \"gpt-4.1-mini-2025-04-14\"\n",
    "\n",
    "# The number of examples to retrieve for the DICL variant.\n",
    "DICL_K = 10\n",
    "\n",
    "# If the metric is a float metric, you can set the threshold to filter the data\n",
    "FLOAT_METRIC_THRESHOLD = 0.5\n",
    "\n",
    "# Whether to use demonstrations for DICL examples\n",
    "USE_DEMONSTRATIONS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8ea49b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from asyncio import Semaphore\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import toml\n",
    "from clickhouse_connect import get_client\n",
    "from openai import AsyncOpenAI\n",
    "from tensorzero.util import uuid7\n",
    "from tqdm.asyncio import tqdm_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8cf25",
   "metadata": {},
   "source": [
    "Load the TensorZero configuration file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e58b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(CONFIG_PATH)\n",
    "\n",
    "assert config_path.exists(), f\"{CONFIG_PATH} does not exist\"\n",
    "assert config_path.is_file(), f\"{CONFIG_PATH} is not a file\"\n",
    "\n",
    "with config_path.open(\"r\") as f:\n",
    "    config = toml.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d999658",
   "metadata": {},
   "source": [
    "Retrieve the configuration for the function we are interested in.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "320d6394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'json', 'output_schema': 'functions/extract_entities/output_schema.json', 'variants': {'gpt_4o': {'type': 'chat_completion', 'model': 'openai::gpt-4o-2024-08-06', 'system_template': 'functions/extract_entities/initial_prompt/system_template.minijinja', 'json_mode': 'strict'}, 'gpt_4o_mini': {'type': 'chat_completion', 'model': 'openai::gpt-4o-mini-2024-07-18', 'system_template': 'functions/extract_entities/initial_prompt/system_template.minijinja', 'json_mode': 'strict'}, 'gpt_4o_mini_fine_tuned': {'type': 'chat_completion', 'model': 'openai::ft:gpt-4.1-mini-2025-04-14:al-test::Bz8DBr4C', 'system_template': 'functions/extract_entities/initial_prompt/system_template.minijinja', 'json_mode': 'strict'}}}\n",
      "json\n"
     ]
    }
   ],
   "source": [
    "assert \"functions\" in config, \"No `[functions]` section found in config\"\n",
    "assert FUNCTION_NAME in config[\"functions\"], (\n",
    "    f\"No function named `{FUNCTION_NAME}` found in config\"\n",
    ")\n",
    "\n",
    "function_config = config[\"functions\"][FUNCTION_NAME]\n",
    "function_type = function_config[\"type\"]\n",
    "print(function_config)\n",
    "print(function_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2af924",
   "metadata": {},
   "source": [
    "Retrieve the metric configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0965565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "if METRIC_NAME is None:\n",
    "    metric = None\n",
    "else:\n",
    "    assert \"metrics\" in config, \"No `[metrics]` section found in config\"\n",
    "    assert METRIC_NAME in config[\"metrics\"], (\n",
    "        f\"No metric named `{METRIC_NAME}` found in config\"\n",
    "    )\n",
    "    metric = config[\"metrics\"][METRIC_NAME]\n",
    "\n",
    "metric\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91be3cd0",
   "metadata": {},
   "source": [
    "Initialize the ClickHouse client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64acef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"TENSORZERO_CLICKHOUSE_URL\" in os.environ, (\n",
    "    \"TENSORZERO_CLICKHOUSE_URL environment variable not set\"\n",
    ")\n",
    "\n",
    "clickhouse_client = get_client(dsn=os.environ[\"TENSORZERO_CLICKHOUSE_URL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306cb0e5",
   "metadata": {},
   "source": [
    "Determine the ClickHouse table name for the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "930c770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_table_name = {\"chat\": \"ChatInference\", \"json\": \"JsonInference\"}.get(\n",
    "    function_type\n",
    ")\n",
    "\n",
    "if inference_table_name is None:\n",
    "    raise ValueError(f\"Unsupported function type: {function_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480980c5",
   "metadata": {},
   "source": [
    "Determine the ClickHouse table name for the metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10bb3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_table_name = (\n",
    "    {\n",
    "        \"float\": \"FloatMetricFeedback\",\n",
    "        \"boolean\": \"BooleanMetricFeedback\",\n",
    "    }.get(metric[\"type\"])\n",
    "    if metric is not None\n",
    "    else None\n",
    ")\n",
    "\n",
    "if feedback_table_name is None and metric is not None:\n",
    "    raise ValueError(f\"Unsupported metric type: {metric['type']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35c10a",
   "metadata": {},
   "source": [
    "Determine the correct join key to use for the metric on the inference table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87813cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_join_key = (\n",
    "    {\n",
    "        \"episode\": \"episode_id\",\n",
    "        \"inference\": \"id\",\n",
    "    }.get(metric[\"level\"])\n",
    "    if metric is not None\n",
    "    else None\n",
    ")\n",
    "\n",
    "if inference_join_key is None and metric is not None:\n",
    "    raise ValueError(f\"Unsupported metric level: {metric['level']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c240652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if metric is not None:\n",
    "    assert \"optimize\" in metric, \"Metric is missing the `optimize` field\"\n",
    "\n",
    "    threshold = FLOAT_METRIC_THRESHOLD if metric[\"type\"] == \"float\" else 0.5\n",
    "    comparison_operator = \">=\" if metric[\"optimize\"] == \"max\" else \"<=\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        i.input,\n",
    "        i.output,\n",
    "    FROM\n",
    "        {inference_table_name} i\n",
    "    JOIN\n",
    "        (SELECT\n",
    "            target_id,\n",
    "            value,\n",
    "            ROW_NUMBER() OVER (PARTITION BY target_id ORDER BY timestamp DESC) as rn\n",
    "        FROM\n",
    "            {feedback_table_name}\n",
    "        WHERE\n",
    "            metric_name = %(metric_name)s\n",
    "            AND value {comparison_operator} %(threshold)s\n",
    "        ) f ON i.{inference_join_key} = f.target_id and f.rn = 1\n",
    "    WHERE\n",
    "        i.function_name = %(function_name)s\n",
    "    \"\"\"\n",
    "\n",
    "    params = {\n",
    "        \"function_name\": FUNCTION_NAME,\n",
    "        \"metric_name\": METRIC_NAME,\n",
    "        \"comparison_operator\": comparison_operator,\n",
    "        \"threshold\": threshold,\n",
    "    }\n",
    "\n",
    "    metric_df = clickhouse_client.query_df(query, params)\n",
    "\n",
    "    metric_df.head()\n",
    "else:\n",
    "    metric_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adae5214",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT\n",
    "    i.input,\n",
    "    f.value AS output\n",
    "FROM\n",
    "    {inference_table_name} i\n",
    "JOIN\n",
    "    (SELECT\n",
    "        inference_id,\n",
    "        value,\n",
    "        ROW_NUMBER() OVER (PARTITION BY inference_id ORDER BY timestamp DESC) as rn\n",
    "    FROM\n",
    "        DemonstrationFeedback\n",
    "    ) f ON i.id = f.inference_id AND f.rn = 1\n",
    "WHERE\n",
    "    i.function_name = %(function_name)s\n",
    "\"\"\"\n",
    "\n",
    "params = {\n",
    "    \"function_name\": FUNCTION_NAME,\n",
    "}\n",
    "\n",
    "if USE_DEMONSTRATIONS:\n",
    "    demonstration_df = clickhouse_client.query_df(query, params)\n",
    "\n",
    "    demonstration_df.head()\n",
    "else:\n",
    "    demonstration_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f31bffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...</td>\n",
       "      <td>{\"raw\":\"{\\\"person\\\":[],\\\"organization\\\":[],\\\"l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...</td>\n",
       "      <td>{\"raw\":\"{\\\"person\\\":[\\\"C. Lewis\\\",\\\"Wasim Akra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...</td>\n",
       "      <td>{\"raw\":\"{\\\"person\\\":[\\\"Glickman\\\"],\\\"organizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...</td>\n",
       "      <td>{\"raw\":\"{\\\"person\\\":[],\\\"organization\\\":[],\\\"l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...</td>\n",
       "      <td>{\"raw\":\"{\\\"person\\\":[\\\"Said\\\"],\\\"organization\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
       "1  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
       "2  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
       "3  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
       "4  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
       "\n",
       "                                              output  \n",
       "0  {\"raw\":\"{\\\"person\\\":[],\\\"organization\\\":[],\\\"l...  \n",
       "1  {\"raw\":\"{\\\"person\\\":[\\\"C. Lewis\\\",\\\"Wasim Akra...  \n",
       "2  {\"raw\":\"{\\\"person\\\":[\\\"Glickman\\\"],\\\"organizat...  \n",
       "3  {\"raw\":\"{\\\"person\\\":[],\\\"organization\\\":[],\\\"l...  \n",
       "4  {\"raw\":\"{\\\"person\\\":[\\\"Said\\\"],\\\"organization\\...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine metric_df and demonstration_df into example_df\n",
    "example_df = pd.concat(\n",
    "    [df for df in [metric_df, demonstration_df] if df is not None], ignore_index=True\n",
    ")\n",
    "\n",
    "# Assert that at least one of the dataframes is not None\n",
    "assert example_df is not None and not example_df.empty, (\n",
    "    \"Both metric_df and demonstration_df are None or empty\"\n",
    ")\n",
    "\n",
    "# Display the first few rows of the combined dataframe\n",
    "example_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc0283b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = AsyncOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb9f7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_embedding(\n",
    "    text: str, semaphore: Semaphore, model: str = \"text-embedding-3-small\"\n",
    ") -> Optional[list[float]]:\n",
    "    try:\n",
    "        async with semaphore:\n",
    "            response = await openai_client.embeddings.create(input=text, model=model)\n",
    "            return response.data[0].embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting embedding: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a610f745",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_CONCURRENT_EMBEDDING_REQUESTS = 50\n",
    "semaphore = Semaphore(MAX_CONCURRENT_EMBEDDING_REQUESTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d53bf6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding inputs: 100%|██████████| 500/500 [00:05<00:00, 96.67it/s] \n"
     ]
    }
   ],
   "source": [
    "# Embed the 'input' column using the get_embedding function\n",
    "tasks = [\n",
    "    get_embedding(str(input_text), semaphore, DICL_EMBEDDING_MODEL)\n",
    "    for input_text in example_df[\"input\"]\n",
    "]\n",
    "embeddings = await tqdm_asyncio.gather(*tasks, desc=\"Embedding inputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "245d25f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
      "1  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
      "2  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
      "3  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
      "4  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
      "\n",
      "                                           embedding  \n",
      "0  [-0.03471248596906662, 0.0012018261477351189, ...  \n",
      "1  [-0.008944535627961159, -0.0022327937185764313...  \n",
      "2  [-0.025813400745391846, 0.009400255978107452, ...  \n",
      "3  [-0.03811752423644066, -0.029765434563159943, ...  \n",
      "4  [0.016340002417564392, -0.0020620147697627544,...  \n"
     ]
    }
   ],
   "source": [
    "# Add the embeddings as a new column to the dataframe\n",
    "example_df[\"embedding\"] = embeddings\n",
    "\n",
    "# Display the first few rows to verify the new column\n",
    "print(example_df[[\"input\", \"embedding\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a5284",
   "metadata": {},
   "source": [
    "Prepare the data for the DynamicInContextLearningExample table\n",
    "The table schema is as follows:\n",
    "\n",
    "```\n",
    "CREATE TABLE tensorzero.DynamicInContextLearningExample\n",
    "(\n",
    "    `id` UUID,\n",
    "    `function_name` LowCardinality(String),\n",
    "    `variant_name` LowCardinality(String),\n",
    "    `namespace` String,\n",
    "    `input` String,\n",
    "    `output` String,\n",
    "    `embedding` Array(Float32),\n",
    "    `timestamp` DateTime MATERIALIZED UUIDv7ToDateTime(id)\n",
    ")\n",
    "ENGINE = MergeTree\n",
    "ORDER BY (function_name, variant_name, namespace)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72936685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'function_name' with the value FUNCTION_NAME for every row\n",
    "example_df[\"function_name\"] = FUNCTION_NAME\n",
    "\n",
    "# Overwrite the 'variant_name' column with the value DICL_VARIANT_NAME for every row\n",
    "example_df[\"variant_name\"] = DICL_VARIANT_NAME\n",
    "\n",
    "# Add a new column 'id' with a UUID for every row\n",
    "example_df[\"id\"] = [uuid7() for _ in range(len(example_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10e219c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>embedding</th>\n",
       "      <th>function_name</th>\n",
       "      <th>variant_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...</td>\n",
       "      <td>{\"raw\":\"{\\\"person\\\":[],\\\"organization\\\":[],\\\"l...</td>\n",
       "      <td>[-0.03471248596906662, 0.0012018261477351189, ...</td>\n",
       "      <td>extract_entities</td>\n",
       "      <td>gpt_4o_mini_dicl</td>\n",
       "      <td>01986213-620a-7b21-a0c3-2a5f422ebf36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...</td>\n",
       "      <td>{\"raw\":\"{\\\"person\\\":[\\\"C. Lewis\\\",\\\"Wasim Akra...</td>\n",
       "      <td>[-0.008944535627961159, -0.0022327937185764313...</td>\n",
       "      <td>extract_entities</td>\n",
       "      <td>gpt_4o_mini_dicl</td>\n",
       "      <td>01986213-620a-7b21-a0c3-2a686f1bb53f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...</td>\n",
       "      <td>{\"raw\":\"{\\\"person\\\":[\\\"Glickman\\\"],\\\"organizat...</td>\n",
       "      <td>[-0.025813400745391846, 0.009400255978107452, ...</td>\n",
       "      <td>extract_entities</td>\n",
       "      <td>gpt_4o_mini_dicl</td>\n",
       "      <td>01986213-620a-7b21-a0c3-2a731e8ffa39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...</td>\n",
       "      <td>{\"raw\":\"{\\\"person\\\":[],\\\"organization\\\":[],\\\"l...</td>\n",
       "      <td>[-0.03811752423644066, -0.029765434563159943, ...</td>\n",
       "      <td>extract_entities</td>\n",
       "      <td>gpt_4o_mini_dicl</td>\n",
       "      <td>01986213-620a-7b21-a0c3-2a8231086fee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...</td>\n",
       "      <td>{\"raw\":\"{\\\"person\\\":[\\\"Said\\\"],\\\"organization\\...</td>\n",
       "      <td>[0.016340002417564392, -0.0020620147697627544,...</td>\n",
       "      <td>extract_entities</td>\n",
       "      <td>gpt_4o_mini_dicl</td>\n",
       "      <td>01986213-620a-7b21-a0c3-2a9752c187e6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
       "1  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
       "2  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
       "3  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
       "4  {\"messages\":[{\"role\":\"user\",\"content\":[{\"type\"...   \n",
       "\n",
       "                                              output  \\\n",
       "0  {\"raw\":\"{\\\"person\\\":[],\\\"organization\\\":[],\\\"l...   \n",
       "1  {\"raw\":\"{\\\"person\\\":[\\\"C. Lewis\\\",\\\"Wasim Akra...   \n",
       "2  {\"raw\":\"{\\\"person\\\":[\\\"Glickman\\\"],\\\"organizat...   \n",
       "3  {\"raw\":\"{\\\"person\\\":[],\\\"organization\\\":[],\\\"l...   \n",
       "4  {\"raw\":\"{\\\"person\\\":[\\\"Said\\\"],\\\"organization\\...   \n",
       "\n",
       "                                           embedding     function_name  \\\n",
       "0  [-0.03471248596906662, 0.0012018261477351189, ...  extract_entities   \n",
       "1  [-0.008944535627961159, -0.0022327937185764313...  extract_entities   \n",
       "2  [-0.025813400745391846, 0.009400255978107452, ...  extract_entities   \n",
       "3  [-0.03811752423644066, -0.029765434563159943, ...  extract_entities   \n",
       "4  [0.016340002417564392, -0.0020620147697627544,...  extract_entities   \n",
       "\n",
       "       variant_name                                    id  \n",
       "0  gpt_4o_mini_dicl  01986213-620a-7b21-a0c3-2a5f422ebf36  \n",
       "1  gpt_4o_mini_dicl  01986213-620a-7b21-a0c3-2a686f1bb53f  \n",
       "2  gpt_4o_mini_dicl  01986213-620a-7b21-a0c3-2a731e8ffa39  \n",
       "3  gpt_4o_mini_dicl  01986213-620a-7b21-a0c3-2a8231086fee  \n",
       "4  gpt_4o_mini_dicl  01986213-620a-7b21-a0c3-2a9752c187e6  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5edd73a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<clickhouse_connect.driver.summary.QuerySummary object at 0x74c14c722b10>\n"
     ]
    }
   ],
   "source": [
    "# Insert the data into the DiclExample table\n",
    "result = clickhouse_client.insert_df(\n",
    "    \"DynamicInContextLearningExample\",\n",
    "    example_df,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c3e195",
   "metadata": {},
   "source": [
    "Finally, add a new variant to your function configuration to try out the Dynamic In-Context Learning variant in practice!\n",
    "\n",
    "If your embedding model name or generation model name in the config is different from the one you used above, you might have to update the config.\n",
    "Be sure and also give the variant some weight and if you are using a JSON function set the json_mode field to \"strict\" if you want.\n",
    "\n",
    "> **Tip:** DICL variants support additional parameters like system instructions or strict JSON mode. See [Configuration Reference](https://www.tensorzero.com/docs/gateway/configuration-reference).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7aa1e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[functions.extract_entities.variants.gpt_4o_mini_dicl]\n",
      "type = \"experimental_dynamic_in_context_learning\"\n",
      "embedding_model = \"text-embedding-3-small\"\n",
      "model = \"gpt-4.1-mini-2025-04-14\"\n",
      "k = 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variant_config = {\n",
    "    \"type\": \"experimental_dynamic_in_context_learning\",\n",
    "    \"embedding_model\": DICL_EMBEDDING_MODEL,\n",
    "    \"model\": DICL_GENERATION_MODEL,\n",
    "    \"k\": DICL_K,\n",
    "}\n",
    "full_variant_config = {\n",
    "    \"functions\": {FUNCTION_NAME: {\"variants\": {DICL_VARIANT_NAME: variant_config}}}\n",
    "}\n",
    "\n",
    "print(toml.dumps(full_variant_config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25767188",
   "metadata": {},
   "source": [
    "If you haven't, also include the embedding model in the config.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ea0d6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[embedding_models.text-embedding-3-small]\n",
      "routing = [ \"openai\",]\n",
      "\n",
      "[embedding_models.text-embedding-3-small.providers.openai]\n",
      "type = \"openai\"\n",
      "model_name = \"text-embedding-3-small\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_model_config = {\n",
    "    \"embedding_models\": {\n",
    "        DICL_EMBEDDING_MODEL: {\n",
    "            \"routing\": [\"openai\"],\n",
    "            \"providers\": {\n",
    "                \"openai\": {\"type\": \"openai\", \"model_name\": DICL_EMBEDDING_MODEL}\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(toml.dumps(embedding_model_config))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py:percent",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
